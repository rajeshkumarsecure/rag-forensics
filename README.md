# Memory Forensics Automation & RAG-Driven Analysis

## Overview
This project provides an end-to-end workflow for:
1. Automatically generating and executing Metasploit payloads against a controlled Ubuntu victim VM from a Kali attacker VM and capturing VMware memory snapshots (VMEM/VMSN).  
2. Normalizing and ingesting indicators of compromise (IoCs) extracted from those memory dumps into a local Qdrant vector database using Azure OpenAI embeddings.  
3. Performing Retrieval-Augmented Generation (RAG)–driven forensic analysis on new memory dumps by correlating live indicators with previously ingested knowledge and producing a structured JSON + HTML incident report.

It is designed for research, repeatable experimentation, and augmentation of traditional memory forensics with LLM reasoning—NOT for production live incident response without further hardening.

## Repository Structure
```
README.md                                  # Project overview, architecture & usage guide
automatic_forensics_pipeline/              # Automated payload generation & memory dump acquisition
  payload_generation.py                    # Generates Metasploit payload artifacts on Kali
  memory_dump_generation.py                # Orchestrates VM snapshotting and payload execution lifecycle
  pipeline_config.json                     # VMware, network, payload, snapshot configuration

rag_driven_forensic_analysis/              # RAG workflow, IoC extraction, similarity ranking & reporting
  analyze_new_memory_dump.py               # Entry point for RAG analysis of a new memory dump
  normalize_and_ingest_into_vector_db.py   # Extracts & normalizes IoCs, embeds, and ingests into Qdrant
  memory_extraction_functions.py           # Volatility3 helper functions for artifact extraction
  rag_utils.py                             # Prompt construction, similarity scoring, ranking helpers
  html_utils.py                            # HTML report rendering utilities
  processing_config.json                   # Azure OpenAI, Qdrant, classification & heuristic config
  requirements.txt                         # Python dependencies (RAG portion)
  images/                                  # Static assets used in HTML report (status & section icons)
    clean.png                              # Icon: clean classification
    default.png                            # Icon: default / neutral state
    ioc.png                                # Icon: Indicators of Compromise section
    malware.png                            # Icon: malicious / threat state
    reasoning.png                          # Icon: reasoning or analytical narrative
    search.png                             # Icon: search / retrieval visualization
    security_recomdation.png               # Icon: security recommendations section
    suspicious.png                         # Icon: suspicious classification indicator
    technical_details.png                  # Icon: technical details section

qdrant_dump/                               # Example persisted snapshot for Qdrant collection restoration
  memory_forensics_analysis-3383796559103186-2025-11-03-18-23-42.snapshot  # Sample snapshot artifact

```
Memory dump artifacts generated by the pipeline should be placed (or will appear) under directories referenced in the config files (e.g. a future `memory_dumps/` path defined in `pipeline_config.json`). Ensure consistent naming if you add such a folder.

## High-Level Architecture
### 1. Automatic Forensics Pipeline (Windows Host + VMs)
- Runs on Windows 11 with VMware Workstation Pro.  
- Attacker VM: Kali Linux (payload generation + Metasploit handler via `tmux`).  
- Victim VM: Ubuntu (payload execution target).  
- Workflow per payload:
  1. Generate payload with `msfvenom` (reverse/bind, IPv4/IPv6 variants).  
  2. Revert victim VM to clean snapshot.  
  3. Transfer payload, set execution permissions, start handler(s).  
  4. Verify network connection establishment.  
  5. Capture VMware snapshot → `.vmem` + `.vmsn` memory dump.  
  6. Copy dump files into `memory_dumps/` for downstream analysis.  
  7. Clean up handlers & snapshots.

### 2. Normalization & Ingestion (Qdrant + Azure OpenAI)
- Volatility3 (invoked via `vol`) parses memory dump to extract:
  - Network connections (direction, protocol heuristics)
  - Process details & mapped memory regions (RWX anomalies)
  - Anonymous or `/dev/zero` RWX mappings
  - YARA string matches (e.g., Meterpreter signatures)
- IoCs and indicator facets are normalized into structured payloads:
  - Text synthesis of indicators
  - Tags (tokenized & stopwords filtered)
  - Specific boolean and keyword facets (e.g., `rwx_to_main_binary`, `connection_facets`)
- Each document embedded with Azure OpenAI embedding model (`text-embedding-3-large`) and stored in Qdrant with associated metadata + optional indices.

### 3. RAG-Driven Dump Analysis
- A fresh memory dump is parsed the same way; indicators become the query.  
- Dense vector similarity + BM25 lexical + token set similarity (Jaccard / precision) re-rank candidate prior cases.  
- A controlled, schema-enforced prompt builds messages for Azure OpenAI `gpt-5-chat`.  
- LLM returns STRICT JSON with classification, MITRE tactics/techniques, reasoning, mapped indicators, and actionable recommendations.  
- HTML report generated with infographic-style sections.

## Features
- Automated multi-payload memory acquisition with snapshot lifecycle management.  
- Support for reverse & bind shells, staged & stageless payload variants.  
- IPv4 + IPv6 unique local address injection.  
- Robust retry logic for payload execution & handler stability.  
- Volatility3-based extraction: network, process, memory maps, YARA hits.  
- Dynamic tokenization of arbitrary indicator schema → robust similarity scoring.  
- Hybrid ranking (dense + BM25 + set similarity).  
- Strict prompt structure mitigating hallucination risk.  
- HTML reporting with threat classification & MITRE mapping.

## Prerequisites
### Host & Virtualization
- Windows 11 with VMware Workstation Pro.  
- Ubuntu victim VM snapshot(s): `clean_snapshot`, `forensics_snapshot` names must exist.  
- Kali attacker VM reachable via SSH.

### Software & Languages
- Python 3.12.x (for automation pipeline on Windows)  
- Python 3.10.x (for Linux forensic/RAG scripts)  
- Metasploit (`msfvenom`, `msfconsole`) on Kali  
- Volatility3 accessible via `vol` command on analysis machine (Linux)  
- Qdrant running locally (`docker run -p 6333:6333 qdrant/qdrant` or native install)  
- Azure OpenAI deployment with:
  - Embedding model: `text-embedding-3-large`
  - Chat model: `gpt-5-chat`

### Python Dependencies (RAG portion)
Install from `rag_driven_forensic_analysis/requirements.txt`:
```
pip install -r rag_driven_forensic_analysis/requirements.txt
```
Additional: Pillow (for HTML image resizing) & Volatility3 if not already installed:
```
wget https://github.com/volatilityfoundation/volatility3/archive/refs/tags/v2.26.2.tar.gz
tar -xvf v2.26.2.tar.gz
pip install --user -e ".[full]"
```
Place the symbol file corresponding to the Linux kernel version of the memory dump you intend to analyze into the volatility3-2.26.2/volatility3/symbols directory before analysis. 

### Create Persistent Qdrant DB
Create a Docker Volume for Qdrant Storage
```
docker volume create qdrant_storage
```
Run Qdrant in Detached Mode
```
docker run -d \
  --name qdrant \
  -p 6333:6333 \
  -p 6334:6334 \
  -v qdrant_storage:/qdrant/storage \
  qdrant/qdrant
```

### SSH Key Setup
Generate and distribute keys from Windows host:
```
ssh-keygen -t rsa
ssh-copy-id user@victim_ip
ssh-copy-id user@attacker_ip
```
Ensure both hosts are added to known_hosts & passwordless SSH works.

## Configuration
### `automatic_forensics_pipeline/pipeline_config.json`
Key fields:
- VMware paths: `ubuntu_vm_folder`, `ubuntu_vm_file`, `Ubuntu_vmsd_file`
- Snapshot names: `clean_snapshot`, `forensics_snapshot`
- Network & credentials: `victim_ip`, `victim_user`, `attacker_ip`, `attacker_user`, etc.
- Ports & interfaces: `attacker_port`, `victim_interface`, `attacker_interface`
- Payload options: `payload_dir`, `payloads[]`, `msfvenom_path`
- IPv6: `victim_ipv6`, `attacker_ipv6`

Replace placeholder values (`<<victim_ip>>`, etc.) with real addresses before running.

### `rag_driven_forensic_analysis/processing_config.json`
Key fields:
- Azure OpenAI: `endpoint_url`, `open_ai_api_key`, `embedding_model`, `gpt_model`, `api_version`
- Qdrant: `qdrant_host`, `qdrant_port`, `qdrant_collection`
- Memory dumps classification mapping: `memory_dumps_classification` (file → label)
- YARA Strings: `suspicious_strings`
- Recommendations: `RemoteShellRecommendations`

You can override sensitive values via environment variables:
```
export ENDPOINT_URL=https://your-endpoint.openai.azure.com/
export AZURE_OPENAI_API_KEY=sk-xxx
export DEPLOYMENT_NAME=text-embedding-3-large  # or chat deployment name when invoked
```

## Usage Workflow
### 1. Generate Payloads (Kali via SSH)
From Windows host:
```
python automatic_forensics_pipeline/payload_generation.py
```
This populates the configured `payload_dir` on the attacker VM.

### 2. Acquire Memory Dumps
```
python automatic_forensics_pipeline/memory_dump_generation.py
```
For each payload:
- Reverts victim VM
- Starts handlers / executes payload
- Verifies connection (TCP/SCTP) & retries if needed
- Captures snapshot and copies `.vmem` & `.vmsn` to `memory_dumps/`

### 3. Ingest Historical Dumps into Qdrant
Run on Ubuntu (analysis machine):
```
python rag_driven_forensic_analysis/normalize_and_ingest_into_vector_db.py
```
This will:
- Parse each dump in `memory_dumps_classification`
- Extract IoCs
- Generate embeddings
- Upsert documents into Qdrant collection

### 4. Analyze a New Memory Dump with RAG
```
python rag_driven_forensic_analysis/analyze_new_memory_dump.py /path/to/new_dump.vmem
```
Produces:
- Console JSON output (structured schema)  
- HTML report: `<dump_basename>_pid_<pid>_report.html`

### 5. Review HTML Report
Open generated `.html` in a browser. Includes classification, MITRE mapping, IoCs, recommendations.

## Restore Sample Qdrant Collection from Snapshot

1. Navigate to the folder containing your snapshot:
```
cd qdrant_dump
```

2. Use the Qdrant API to restore the collection from the snapshot:
```
curl -X PUT "http://localhost:6333/collections/memory_forensics_analysis/snapshots/recover?wait=true" \
  -H "api-key: <<api_key>>" \
  -H "Content-Type: application/json" \
  -d '{
    "location": "file:///qdrant/snapshots/memory_forensics_analysis/memory_forensics_analysis-3383796559103186-2025-11-03-18-23-42.snapshot",
    "priority": "snapshot"
  }'
```
3. Verify the collection is restored:
```
curl -s "http://localhost:6333/collections" -H "api-key: <<api_key>>" | jq
```

## Indicator Logic & Heuristics
- Network direction inferred via ephemeral vs privileged port ranges; special ports flagged as suspicious.  
- RWX memory regions mapped to main binary / anonymous / `/dev/zero` treated as potential injection indicators.  
- YARA strings matched for Meterpreter or provided signatures.  
- Tokenization flattens arbitrary indicator schema into `key=value` facets for similarity comparison (no hardcoded categories needed).  
- Re-ranking blends:  
  - Dense cosine similarity (Qdrant)  
  - BM25 lexical overlap (text + tags)  
  - Jaccard token similarity  

## Output Schema (LLM)
Fields returned (strict JSON):
- `observation` (list of high-level points without dynamic identifiers)
- `Technical Details` (artifact-rich enumerations: ports, processes, memory regions)
- `Threat`, `classification`, `confidence`
- `Tactics` & `Techniques` + reasoning lists
- `matched_rag_indicators` (intersection tokens)
- `Security Recommendations` (actionable mitigations)

## Extensibility Ideas
- Integrate live sandbox execution + differential memory comparison.  
- Expand protocol heuristics (SCTP/ICMP/IPv6 flows).  
- Add provenance tracking & versioning for ingested points.  
- Implement CLI flags for selective payload execution or concurrency.  
- Integrate streaming LLM responses + incremental reasoning traces.

## Security & Ethics
- Only use in isolated lab environments; executing payloads is inherently risky.  
- Do not deploy against systems you do not own or have authorization to test.  
- Clean up artifacts and credentials post-experiment.  
- Treat generated dumps as sensitive; they may contain secrets or authentication material.  

## Troubleshooting
| Symptom | Possible Cause | Resolution |
| ------- | -------------- | ---------- |
| Empty IoC list | Wrong dump profile / Volatility plugin mismatch | Verify Volatility install & Linux profile support |
| No handler connection | Firewall or wrong `LHOST`/`RHOST` | Confirm IP config & port, retry automatically or manually |
| Qdrant errors on upsert | Collection not created / vector length mismatch | Let script create collection or validate embedding model consistency |
| JSON parse failure in analysis | Model returned non-JSON content | Re-run; ensure prompt integrity & sufficient `max_completion_tokens` |

## Known Limitations
- Heuristic port direction detection may misclassify uncommon service mappings.  
- RWX mapping detection relies on simple pattern matching; advanced injection may evade.  
- MITRE mapping is LLM-derived; requires human validation for high-stakes decisions.  
- No authentication layer on Qdrant (local only).  

## Quick Start Summary
1. Configure `pipeline_config.json` & `processing_config.json`.  
2. Generate payloads.  
3. Acquire memory dumps.  
4. Ingest historical dumps.  
5. Analyze a new dump → JSON + HTML report.  

## Authors
Project Created by Rajesh Kumar Natarajan[@rajeshkumarsecure](https://github.com/rajeshkumarsecure), Srinivasan Govindarajan[@svsrinigk](https://github.com/svsrinigk) & Pranjal Gupta [@pranjal2209](https://github.com/pranjal2209)

## Disclaimer
This project is for educational & research purposes. The authors are not responsible for misuse. Ensure compliance with local laws and organizational policies.

---
Feel free to open issues or extend modules (`memory_extraction_functions.py`, `rag_utils.py`) for new artifact types.
